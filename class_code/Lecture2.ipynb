{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJ1ZgR7XSMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from sklearn import datasets, model_selection\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJGYB1tJUv_9",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression, manual in python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R66JhXaXBhVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = datasets.load_digits(return_X_y=True)\n",
        "zero_or_one = np.logical_or(y==0, y==1)\n",
        "X = X[zero_or_one,:]\n",
        "y = y[zero_or_one]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySfrk9yQBs-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = np.random.randint(0, X.shape[0])\n",
        "_ = plt.imshow(X[idx, :].reshape(8, 8), cmap=plt.cm.gray)\n",
        "_ = plt.axis('off')\n",
        "print(f'The label is {y[idx]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-dhLdsQFKFr",
        "colab_type": "text"
      },
      "source": [
        "Reminder: Sigmoid function is \n",
        "\n",
        "```\n",
        "f(x) = 1/(1+exp(w_0 + x_1*w_1 + x_2*w_2 ...))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPDbekkWCzGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_training_data(X, y):\n",
        "  X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, shuffle=True, train_size=0.8, test_size=0.2)\n",
        "  \n",
        "  for idx in range(X_train.shape[1]):\n",
        "    m = X_train[:, idx].mean()\n",
        "    s = X_train[:, idx].std()\n",
        "    if s > 0:\n",
        "      X_train[:, idx] = (X_train[:, idx] - m)/s\n",
        "      X_test[:, idx] = (X_test[:, idx] - m)/s\n",
        "      \n",
        "  X_train = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), 1)\n",
        "  X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), 1)\n",
        "    \n",
        "  return X_train, X_test, y_train.ravel(), y_test.ravel()\n",
        "\n",
        "X_train, X_test, y_train, y_test = setup_training_data(X, y)\n",
        "print(X_train[:, 0].mean())\n",
        "print(X_train[:, 0].std())\n",
        "print(X_train[:, 2].mean())\n",
        "print(X_train[:, 2].std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqovS9-Ckhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_logistic(X):\n",
        "  w = np.random.randn(X.shape[1], 1)\n",
        "  return w\n",
        "\n",
        "w = setup_logistic(X_train)\n",
        "\n",
        "def sigmoid(X, w):\n",
        "  '''Returns a the sigmoid function specified the input matrix and weights'''\n",
        "  res = 1/(1 + np.exp(-np.dot(X, w)))\n",
        "  return res.ravel()\n",
        "\n",
        "def accuracy(y, y_hat):\n",
        "  y_hat = (y_hat > 0.5).astype('int').ravel()\n",
        "  y = y.astype('int').ravel()\n",
        "  res = np.sum(y == y_hat)\n",
        "  return res.astype('float') / len(y) \n",
        "\n",
        "y_hat = sigmoid(X_train, w)\n",
        "print(accuracy(y_train, y_hat))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFINnClGOWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.0001\n",
        "\n",
        "w = setup_logistic(X_train)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  y_hat = sigmoid(X_train, w)\n",
        "  err = y_train - y_hat\n",
        "  update_mat = np.expand_dims(np.dot(X_train.T, err), 1)\n",
        "  w = w + learning_rate * update_mat\n",
        "\n",
        "  y_hat = sigmoid(X_train, w)\n",
        "  acc = accuracy(y_train, y_hat)\n",
        "  print(f'On epoch {epoch} the training accuracy of the model is {acc:0.3f}')\n",
        "  \n",
        "  y_hat_test = sigmoid(X_test, w)\n",
        "  test_acc = accuracy(y_test, y_hat_test)\n",
        "  print(f'On epoch {epoch} the test accuracy of the model is {test_acc:0.3f}')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzKEt-5UeOI",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression in Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvi2IJHpUcoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rCmov_WUqBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset = dataset.dropna()\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYN8LGVhUuhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin = dataset.pop('Origin')\n",
        "\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXN-a0XlVaMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4ibhfKIVf_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQxNkOFMVjgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o9owE-oVpgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWSJwOe8WAfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "      layers.Dense(1, activation='linear', input_shape=[len(train_dataset.keys())])\n",
        "  ])\n",
        "  optimizer = tf.keras.optimizers.SGD(0.01)\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsnWqU1EWQ7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inKA50psWUH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLwj8-AJdO1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4O3dwSgdUwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbTYB5lgdXmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Ed8qQAJGOO",
        "colab_type": "text"
      },
      "source": [
        "# Automatic Differentiation in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "133qUrlFJpxo",
        "colab_type": "text"
      },
      "source": [
        "## Gradient tapes\n",
        "\n",
        "TensorFlow provides the [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a `tf.GradientTape` onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using [reverse mode differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15TnkNtAJKBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.ones((2, 2))\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  z = tf.multiply(y, y)\n",
        "\n",
        "# Derivative of z with respect to the original input tensor x\n",
        "dz_dx = t.gradient(z, x)\n",
        "for i in [0, 1]:\n",
        "  for j in [0, 1]:\n",
        "    assert dz_dx[i][j].numpy() == 8.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hil4z-YfJtzM",
        "colab_type": "text"
      },
      "source": [
        "You can also request gradients of the output with respect to intermediate values computed during a \"recorded\" `tf.GradientTape` context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42vOJDOIJx5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.ones((2, 2))\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  z = tf.multiply(y, y)\n",
        "\n",
        "# Use the tape to compute the derivative of z with respect to the\n",
        "# intermediate value y.\n",
        "dz_dy = t.gradient(z, y)\n",
        "assert dz_dy.numpy() == 8.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBEdKMWJJ2tP",
        "colab_type": "text"
      },
      "source": [
        "By default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a `persistent` gradient tape. This allows multiple calls to the `gradient()` method as resources are released when the tape object is garbage collected. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0cez6_6J5gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape(persistent=True) as t:\n",
        "  t.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
        "dy_dx = t.gradient(y, x)  # 6.0\n",
        "del t  # Drop the reference to the tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sASZElzQJ8Sv",
        "colab_type": "text"
      },
      "source": [
        "### Recording control flow\n",
        "\n",
        "Because tapes record operations as they are executed, Python control flow (using `if`s and `while`s for example) is naturally handled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWXwch84J_YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x, y):\n",
        "  output = 1.0\n",
        "  for i in range(y):\n",
        "    if i > 1 and i < 5:\n",
        "      output = tf.multiply(output, x)\n",
        "  return output\n",
        "\n",
        "def grad(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    out = f(x, y)\n",
        "  return t.gradient(out, x)\n",
        "\n",
        "x = tf.convert_to_tensor(2.0)\n",
        "\n",
        "assert grad(x, 6).numpy() == 12.0\n",
        "assert grad(x, 5).numpy() == 12.0\n",
        "assert grad(x, 4).numpy() == 4.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czlGiZ6fKHpG",
        "colab_type": "text"
      },
      "source": [
        "### Higher-order gradients\n",
        "\n",
        "Operations inside of the `GradientTape` context manager are recorded for automatic differentiation. If gradients are computed in that context, then the gradient computation is recorded as well. As a result, the exact same API works for higher-order gradients as well. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUJ9fHLPKJ5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(1.0)  # Create a Tensorflow variable initialized to 1.0\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  with tf.GradientTape() as t2:\n",
        "    y = x * x * x\n",
        "  # Compute the gradient inside the 't' context manager\n",
        "  # which means the gradient computation is differentiable as well.\n",
        "  dy_dx = t2.gradient(y, x)\n",
        "d2y_dx2 = t.gradient(dy_dx, x)\n",
        "\n",
        "assert dy_dx.numpy() == 3.0\n",
        "assert d2y_dx2.numpy() == 6.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iUeDM7kHvtg",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Neural Network Exampe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiyWZA5IHvQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt_kkWS5H2HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_CGNI-H62q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}