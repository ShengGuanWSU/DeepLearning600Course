{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZyEcDsgSaM",
        "colab_type": "code",
        "outputId": "66105a98-50aa-486c-80e8-709e9724f7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_yl4WEZfL9w",
        "colab_type": "code",
        "outputId": "81856218-505f-49e9-96a5-533f960df2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouZFzD9sgKIA",
        "colab_type": "text"
      },
      "source": [
        "# Setup the training samples\n",
        "\n",
        "Training data is Gaussian samples with a pre-defined mean and standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuCedvoliqnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_sample(n_samples=128, dim=50, mean=0, std=1):\n",
        "  mat = np.random.normal(loc=mean, scale=std, size=(n_samples, dim))\n",
        "  mat.sort()\n",
        "  return mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyZyroWVjadP",
        "colab_type": "code",
        "outputId": "7319cb0d-01ea-461a-d3fd-7af9f44672eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "mat = training_sample(dim=10)\n",
        "print(mat[0:2, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.75050074 -0.72253882 -0.35760376 -0.29982809  0.23237048  0.26906279\n",
            "   0.28971933  0.43138832  1.19139298  1.93532075]\n",
            " [-1.37061519 -1.04092146 -0.75376388  0.00981307  0.22052643  0.3381397\n",
            "   0.34901661  0.44907991  0.94495528  1.1191419 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XutyWqNggRTD",
        "colab_type": "text"
      },
      "source": [
        "# Setup the noise input to the generator\n",
        "\n",
        "The noise we are using is uniform random samples from -1.0 to 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhuoCsmOa5X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uniform_noise(n_samples=128, dim=50):\n",
        "  mat = np.random.uniform(low=-1., high=1., size=(n_samples, dim))\n",
        "  return mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFM9ObBzbWZK",
        "colab_type": "code",
        "outputId": "1e2b0daa-f0d2-4a5d-99c2-daa9dd5536bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "mat = uniform_noise()\n",
        "print(mat[0:2, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.56946917  0.20844781 -0.18082493 -0.62380278  0.96479448 -0.20365066\n",
            "   0.10410229  0.63647361 -0.90328749  0.74835686 -0.15113764  0.71952157\n",
            "   0.40791592  0.31208863  0.98355927  0.2401992   0.77136015 -0.68569544\n",
            "  -0.55937574 -0.17175934 -0.48929637 -0.96144658  0.52999217 -0.10633466\n",
            "  -0.59422936 -0.57054272 -0.58063938 -0.18546508 -0.34491658  0.79083052\n",
            "  -0.27503379 -0.17260148  0.05798013  0.5035693  -0.91520024  0.84017776\n",
            "   0.88432303 -0.28952139  0.77375623  0.61841898 -0.96409122  0.65630194\n",
            "   0.73581476  0.27428745 -0.90281215  0.77637039 -0.61455694 -0.16035977\n",
            "   0.10259753  0.60021942]\n",
            " [ 0.96962407 -0.47929262  0.50427257 -0.08626526  0.58259596  0.79573265\n",
            "  -0.09238911  0.73430327  0.43485479  0.52952049  0.12012887 -0.9115758\n",
            "  -0.35792351 -0.82258417 -0.94273216  0.52080386  0.37798167  0.54233422\n",
            "  -0.85103419 -0.33111009  0.31285366  0.4890387  -0.28751304  0.31322476\n",
            "   0.62096418 -0.26369079 -0.25443896 -0.08053447 -0.1529356  -0.63603062\n",
            "   0.7014213   0.08758825  0.5204268   0.97354859 -0.11791512  0.86717255\n",
            "  -0.20786407 -0.29535448 -0.55878581 -0.86465273  0.68899526 -0.66762768\n",
            "   0.41607949 -0.0451882   0.03659209  0.26457247  0.54004085  0.95239299\n",
            "   0.50530321  0.7692773 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mjOx-GpgZ6R",
        "colab_type": "text"
      },
      "source": [
        "# Setup the generator\n",
        "\n",
        "The generator takes in an input matrix setup above. The model is a multi-layer network with an output dimension that is the same dimension as the training data. The final step is to sort the training data similar to how the training samples are created.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2a5yX5pbaJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator(input_dim=50, output_dim=50):\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(input_dim,))\n",
        "  x = tf.keras.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
        "  outputs = tf.keras.layers.Dense(output_dim, activation='linear')(x)\n",
        "  #outputs = tf.sort(x, axis=-1, direction='ASCENDING', name=\"sort_outputs\")\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eVx58DQdTLj",
        "colab_type": "code",
        "outputId": "ea9a23f9-9a1c-4c9c-c5b0-0e62370f17e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "generator = make_generator()\n",
        "print(generator.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                1650      \n",
            "=================================================================\n",
            "Total params: 3,282\n",
            "Trainable params: 3,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH02BAUseqmi",
        "colab_type": "code",
        "outputId": "16b9b6e1-0674-412b-d1b9-84df1d4d956d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "noise = uniform_noise()\n",
        "result = generator(noise, training=False)\n",
        "print(result.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.41411746  0.22913745 -0.24338296 ... -0.4135636   0.18903458\n",
            "   0.00357657]\n",
            " [ 0.0893088   0.2531884   0.06489225 ... -0.5079901  -0.09333082\n",
            "  -0.02859536]\n",
            " [ 0.03116179  0.07244159  0.2864731  ...  0.2757517  -0.7458199\n",
            "   0.01255361]\n",
            " ...\n",
            " [-0.6955908   0.4217471  -0.00477989 ... -1.0270151   0.56408024\n",
            "   0.3049831 ]\n",
            " [ 0.30069786 -0.6426348   0.16419655 ... -0.8890141   0.48763275\n",
            "   0.31010646]\n",
            " [ 0.18888508  0.4096608  -0.45464355 ... -0.1222515   0.34185013\n",
            "  -0.679326  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJnkkFBugsYO",
        "colab_type": "text"
      },
      "source": [
        "# Setup the discriminator\n",
        "The discriminator takes in a sample and predicts whether it is a training or testing sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDt51hAcfnDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator(input_dim=50, output_dim=1):\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(input_dim,))\n",
        "  x = tf.keras.layers.Dense(16, activation=tf.nn.relu)(inputs)\n",
        "  outputs = tf.keras.layers.Dense(output_dim, activation='sigmoid')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eWWfmYAf3di",
        "colab_type": "code",
        "outputId": "bd0d9c83-e449-4944-9aa5-991110de3a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "discriminator = make_discriminator()\n",
        "print(discriminator.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 833\n",
            "Trainable params: 833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JnJQBdog5xw",
        "colab_type": "code",
        "outputId": "2d20f658-f820-4dec-9157-4a408bafa09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "generated_sample = generator(uniform_noise(n_samples=5))\n",
        "result = discriminator(generated_sample)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.696931  ]\n",
            " [0.45723337]\n",
            " [0.6949912 ]\n",
            " [0.6294236 ]\n",
            " [0.7148362 ]], shape=(5, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsPNI5C2hI1V",
        "colab_type": "text"
      },
      "source": [
        "# Setup the loss and optimizer\n",
        "We setup two optimizers, one for the generator, one for the discriminator. These are taken from https://www.tensorflow.org/tutorials/generative/dcgan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWzeyeebhCeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILVSwbzIhSI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS4yNAKLhiDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSrpIJb7hvB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(5e-3)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(5e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMlncUROh2IC",
        "colab_type": "text"
      },
      "source": [
        "# Setup the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdO23eMh1Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD7XSZ8Wh4v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(generator, discriminator, mean=0., std=1.):\n",
        "  noise = tf.random.uniform((128, 50), minval=-1., maxval=1.)\n",
        "  train_sample = tf.random.normal(\n",
        "    (128, 50),\n",
        "    mean=mean,\n",
        "    stddev=std,\n",
        "  )\n",
        "  train_sample = tf.sort(train_sample, axis=-1, direction='ASCENDING')\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_samples = generator(noise, training=True)\n",
        "\n",
        "    real_output = discriminator(train_sample, training=True)\n",
        "    fake_output = discriminator(generated_samples, training=True)\n",
        "\n",
        "    gen_loss = 4*generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "  return gen_loss, disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF7CTM-0ii7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs=1000, num_batches=100, mean=1., std=3.):\n",
        "  generator = make_generator()\n",
        "  discriminator = make_discriminator()\n",
        "  gens = []\n",
        "  discs = []\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    for batch in range(num_batches):\n",
        "      gen_loss, disc_loss = train_step(generator, discriminator, mean=mean, std=std)\n",
        "    eval_sample = tf.random.uniform((1, 50), minval=-1., maxval=1.)\n",
        "    result = generator(eval_sample)\n",
        "    gen = gen_loss.numpy().mean()\n",
        "    disc = disc_loss.numpy().mean()\n",
        "    gens.append(gen)\n",
        "    discs.append(disc)\n",
        "    print(f'On epoch {epoch} the generator loss is {gen:.2f}, the discriminator loss is {disc:.2f}')\n",
        "  return gens, discs, generator, discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETxpAbTvjiD1",
        "colab_type": "code",
        "outputId": "0a278bf8-400e-454f-a012-944d9e87f283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gens, discs, generator, discriminator = train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "On epoch 1 the generator loss is 2.76, the discriminator loss is 1.01\n",
            "On epoch 2 the generator loss is 2.59, the discriminator loss is 1.07\n",
            "On epoch 3 the generator loss is 2.18, the discriminator loss is 1.24\n",
            "On epoch 4 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 5 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 6 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 7 the generator loss is 2.14, the discriminator loss is 1.28\n",
            "On epoch 8 the generator loss is 2.23, the discriminator loss is 1.24\n",
            "On epoch 9 the generator loss is 2.14, the discriminator loss is 1.34\n",
            "On epoch 10 the generator loss is 2.53, the discriminator loss is 1.10\n",
            "On epoch 11 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 12 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 13 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 14 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 15 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 16 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 17 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 18 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 19 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 20 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 21 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 22 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 23 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 24 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 25 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 26 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 27 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 28 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 29 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 30 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 31 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 32 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 33 the generator loss is 2.43, the discriminator loss is 1.16\n",
            "On epoch 34 the generator loss is 2.77, the discriminator loss is 1.11\n",
            "On epoch 35 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 36 the generator loss is 2.67, the discriminator loss is 1.05\n",
            "On epoch 37 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 38 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 39 the generator loss is 2.76, the discriminator loss is 1.01\n",
            "On epoch 40 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 41 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 42 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 43 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 44 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 45 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 46 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 47 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 48 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 49 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 50 the generator loss is 2.62, the discriminator loss is 1.07\n",
            "On epoch 51 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 52 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 53 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 54 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 55 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 56 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 57 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 58 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 59 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 60 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 61 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 62 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 63 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 64 the generator loss is 2.74, the discriminator loss is 1.02\n",
            "On epoch 65 the generator loss is 2.76, the discriminator loss is 1.01\n",
            "On epoch 66 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 67 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 68 the generator loss is 2.76, the discriminator loss is 1.01\n",
            "On epoch 69 the generator loss is 2.77, the discriminator loss is 1.01\n",
            "On epoch 70 the generator loss is 2.75, the discriminator loss is 1.02\n",
            "On epoch 71 the generator loss is 2.28, the discriminator loss is 1.20\n",
            "On epoch 72 the generator loss is 2.49, the discriminator loss is 1.11\n",
            "On epoch 73 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 74 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 75 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 76 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 77 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 78 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 79 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 80 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 81 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 82 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 83 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 84 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 85 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 86 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 87 the generator loss is 1.26, the discriminator loss is 1.63\n",
            "On epoch 88 the generator loss is 1.34, the discriminator loss is 1.59\n",
            "On epoch 89 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 90 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 91 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 92 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 93 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 94 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 95 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 96 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 97 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 98 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 99 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 100 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 101 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 102 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 103 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 104 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 105 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 106 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 107 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 108 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 109 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 110 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 111 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 112 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 113 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 114 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 115 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 116 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 117 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 118 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 119 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 120 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 121 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 122 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 123 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 124 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 125 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 126 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 127 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 128 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 129 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 130 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 131 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 132 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 133 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 134 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 135 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 136 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 137 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 138 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 139 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 140 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 141 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 142 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 143 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 144 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 145 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 146 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 147 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 148 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 149 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 150 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 151 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 152 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 153 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 154 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 155 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 156 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 157 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 158 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 159 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 160 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 161 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 162 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 163 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 164 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 165 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 166 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 167 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 168 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 169 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 170 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 171 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 172 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 173 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 174 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 175 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 176 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 177 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 178 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 179 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 180 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 181 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 182 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 183 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 184 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 185 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 186 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 187 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 188 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 189 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 190 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 191 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 192 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 193 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 194 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 195 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 196 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 197 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 198 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 199 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 200 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 201 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 202 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 203 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 204 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 205 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 206 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 207 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 208 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 209 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 210 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 211 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 212 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 213 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 214 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 215 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 216 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 217 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 218 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 219 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 220 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 221 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 222 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 223 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 224 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 225 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 226 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 227 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 228 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 229 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 230 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 231 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 232 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 233 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 234 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 235 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 236 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 237 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 238 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 239 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 240 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 241 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 242 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 243 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 244 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 245 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 246 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 247 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 248 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 249 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 250 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 251 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 252 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 253 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 254 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 255 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 256 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 257 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 258 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 259 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 260 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 261 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 262 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 263 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 264 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 265 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 266 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 267 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 268 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 269 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 270 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 271 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 272 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 273 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 274 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 275 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 276 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 277 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 278 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 279 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 280 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 281 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 282 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 283 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 284 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 285 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 286 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 287 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 288 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 289 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 290 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 291 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 292 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 293 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 294 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 295 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 296 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 297 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 298 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 299 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 300 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 301 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 302 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 303 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 304 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 305 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 306 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 307 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 308 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 309 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 310 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 311 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 312 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 313 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 314 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 315 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 316 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 317 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 318 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 319 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 320 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 321 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 322 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 323 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 324 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 325 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 326 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 327 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 328 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 329 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 330 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 331 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 332 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 333 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 334 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 335 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 336 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 337 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 338 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 339 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 340 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 341 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 342 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 343 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 344 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 345 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 346 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 347 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 348 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 349 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 350 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 351 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 352 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 353 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 354 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 355 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 356 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 357 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 358 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 359 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 360 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 361 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 362 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 363 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 364 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 365 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 366 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 367 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 368 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 369 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 370 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 371 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 372 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 373 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 374 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 375 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 376 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 377 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 378 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 379 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 380 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 381 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 382 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 383 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 384 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 385 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 386 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 387 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 388 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 389 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 390 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 391 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 392 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 393 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 394 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 395 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 396 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 397 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 398 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 399 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 400 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 401 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 402 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 403 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 404 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 405 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 406 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 407 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 408 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 409 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 410 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 411 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 412 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 413 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 414 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 415 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 416 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 417 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 418 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 419 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 420 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 421 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 422 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 423 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 424 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 425 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 426 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 427 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 428 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 429 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 430 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 431 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 432 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 433 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 434 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 435 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 436 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 437 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 438 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 439 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 440 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 441 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 442 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 443 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 444 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 445 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 446 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 447 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 448 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 449 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 450 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 451 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 452 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 453 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 454 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 455 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 456 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 457 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 458 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 459 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 460 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 461 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 462 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 463 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 464 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 465 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 466 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 467 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 468 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 469 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 470 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 471 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 472 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 473 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 474 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 475 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 476 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 477 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 478 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 479 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 480 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 481 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 482 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 483 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 484 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 485 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 486 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 487 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 488 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 489 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 490 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 491 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 492 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 493 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 494 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 495 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 496 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 497 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 498 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 499 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 500 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 501 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 502 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 503 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 504 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 505 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 506 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 507 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 508 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 509 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 510 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 511 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 512 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 513 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 514 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 515 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 516 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 517 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 518 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 519 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 520 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 521 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 522 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 523 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 524 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 525 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 526 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 527 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 528 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 529 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 530 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 531 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 532 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 533 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 534 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 535 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 536 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 537 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 538 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 539 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 540 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 541 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 542 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 543 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 544 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 545 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 546 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 547 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 548 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 549 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 550 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 551 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 552 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 553 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 554 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 555 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 556 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 557 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 558 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 559 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 560 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 561 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 562 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 563 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 564 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 565 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 566 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 567 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 568 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 569 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 570 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 571 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 572 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 573 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 574 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 575 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 576 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 577 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 578 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 579 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 580 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 581 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 582 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 583 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 584 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 585 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 586 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 587 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 588 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 589 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 590 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 591 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 592 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 593 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 594 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 595 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 596 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 597 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 598 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 599 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 600 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 601 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 602 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 603 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 604 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 605 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 606 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 607 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 608 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 609 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 610 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 611 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 612 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 613 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 614 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 615 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 616 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 617 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 618 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 619 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 620 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 621 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 622 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 623 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 624 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 625 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 626 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 627 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 628 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 629 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 630 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 631 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 632 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 633 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 634 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 635 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 636 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 637 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 638 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 639 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 640 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 641 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 642 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 643 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 644 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 645 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 646 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 647 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 648 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 649 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 650 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 651 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 652 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 653 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 654 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 655 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 656 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 657 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 658 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 659 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 660 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 661 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 662 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 663 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 664 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 665 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 666 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 667 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 668 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 669 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 670 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 671 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 672 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 673 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 674 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 675 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 676 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 677 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 678 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 679 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 680 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 681 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 682 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 683 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 684 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 685 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 686 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 687 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 688 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 689 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 690 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 691 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 692 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 693 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 694 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 695 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 696 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 697 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 698 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 699 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 700 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 701 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 702 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 703 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 704 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 705 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 706 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 707 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 708 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 709 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 710 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 711 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 712 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 713 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 714 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 715 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 716 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 717 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 718 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 719 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 720 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 721 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 722 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 723 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 724 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 725 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 726 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 727 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 728 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 729 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 730 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 731 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 732 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 733 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 734 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 735 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 736 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 737 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 738 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 739 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 740 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 741 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 742 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 743 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 744 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 745 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 746 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 747 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 748 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 749 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 750 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 751 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 752 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 753 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 754 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 755 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 756 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 757 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 758 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 759 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 760 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 761 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 762 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 763 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 764 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 765 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 766 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 767 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 768 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 769 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 770 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 771 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 772 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 773 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 774 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 775 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 776 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 777 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 778 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 779 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 780 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 781 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 782 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 783 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 784 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 785 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 786 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 787 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 788 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 789 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 790 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 791 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 792 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 793 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 794 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 795 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 796 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 797 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 798 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 799 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 800 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 801 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 802 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 803 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 804 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 805 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 806 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 807 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 808 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 809 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 810 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 811 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 812 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 813 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 814 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 815 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 816 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 817 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 818 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 819 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 820 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 821 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 822 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 823 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 824 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 825 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 826 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 827 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 828 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 829 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 830 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 831 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 832 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 833 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 834 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 835 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 836 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 837 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 838 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 839 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 840 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 841 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 842 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 843 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 844 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 845 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 846 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 847 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 848 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 849 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 850 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 851 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 852 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 853 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 854 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 855 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 856 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 857 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 858 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 859 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 860 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 861 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 862 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 863 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 864 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 865 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 866 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 867 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 868 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 869 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 870 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 871 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 872 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 873 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 874 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 875 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 876 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 877 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 878 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 879 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 880 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 881 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 882 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 883 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 884 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 885 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 886 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 887 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 888 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 889 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 890 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 891 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 892 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 893 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 894 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 895 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 896 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 897 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 898 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 899 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 900 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 901 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 902 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 903 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 904 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 905 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 906 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 907 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 908 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 909 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 910 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 911 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 912 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 913 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 914 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 915 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 916 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 917 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 918 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 919 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 920 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 921 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 922 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 923 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 924 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 925 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 926 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 927 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 928 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 929 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 930 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 931 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 932 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 933 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 934 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 935 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 936 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 937 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 938 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 939 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 940 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 941 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 942 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 943 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 944 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 945 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 946 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 947 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 948 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 949 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 950 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 951 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 952 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 953 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 954 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 955 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 956 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 957 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 958 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 959 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 960 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 961 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 962 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 963 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 964 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 965 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 966 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 967 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 968 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 969 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 970 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 971 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 972 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 973 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 974 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 975 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 976 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 977 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 978 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 979 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 980 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 981 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 982 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 983 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 984 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 985 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 986 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 987 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 988 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 989 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 990 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 991 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 992 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 993 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 994 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 995 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 996 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 997 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 998 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 999 the generator loss is 1.25, the discriminator loss is 1.63\n",
            "On epoch 1000 the generator loss is 1.25, the discriminator loss is 1.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCagJBlOpT7W",
        "colab_type": "code",
        "outputId": "82dc6293-1eec-4b6f-efd0-5233f75cc61d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "noise = tf.random.uniform((10, 50), minval=-1., maxval=1.)\n",
        "generated_samples = generator(noise, training=False)\n",
        "fake_output = discriminator(generated_samples, training=False)\n",
        "print(fake_output.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vam5pwrApvDX",
        "colab_type": "code",
        "outputId": "db26afcb-7310-4fc1-91e1-23bec44832f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_sample = tf.random.normal(\n",
        "    (10, 50),\n",
        "    mean=1,\n",
        "    stddev=3,\n",
        "  )\n",
        "train_sample = tf.sort(train_sample, axis=-1, direction='ASCENDING')\n",
        "real_output = discriminator(train_sample, training=False)\n",
        "print(real_output.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMMbIPFZDsYC",
        "colab_type": "code",
        "outputId": "fb0487f9-ddb7-4cff-887d-989ccd46c217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "noise = tf.random.uniform((1, 50), minval=-1., maxval=1.)\n",
        "generated_sample = generator(noise).numpy().ravel()\n",
        "print(generated_sample.mean(), generated_sample.std())\n",
        "plt.hist(generated_sample)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.9387653 13.853054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3., 6., 7., 7., 7., 2., 7., 5., 0., 6.]),\n",
              " array([-20.348656 , -15.358021 , -10.367385 ,  -5.37675  ,  -0.3861145,\n",
              "          4.604521 ,   9.595156 ,  14.585792 ,  19.576427 ,  24.567062 ,\n",
              "         29.557697 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nljd/mM12AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJBMyyvFj9BW",
        "colab_type": "code",
        "outputId": "8f8245b3-123d-4815-bebc-d9accfaf6810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(range(len(gens)), gens, range(len(discs)), discs)\n",
        "plt.legend(['Generator Loss', 'Discriminator Loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0343e65470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhJzCnoRkZj7/91Hq3sifRg7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}